{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling - Mass Stock Price Download using yfinance package, Technical Analysis, and Final Data Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this workbook is 1 of 4 scraping and extracting processes that ultimately aggregate into the Technical Indicators workbook in the Data Wrangling phase of capstone 3\n",
    "\n",
    "\n",
    "* Fundamental Scraper - scrapes 5 years worth of fundamental company financial data from MarketWatch using Beautiful Soup from the S&P 500 list\n",
    "* Fundamental Calcs - imports scraped data from the scraper tool, converts text data to numeric - i.e. 5.00M to 5000000 - using regular expressions, and calculates additonal financial metrics\n",
    "* Analyst Scraper - scrapes analyst buy, sell, hold ratings for all S&P 500 stocks and downloads to .csv file\n",
    "\n",
    "* <span style=\"color:red\"> **Mass Yahoo Download (this book)** </span> - downloads 5 years of daily stock pricing data from the S&P 500, Runs complex Directional Index, ADX, Bollinger Band, and other financial charting data. Merges data from fundamental and analyst scrapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\Stock Import Lists'\n",
    "importfile = 'SandP.csv'\n",
    "exportpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData'\n",
    "exportfile = 'Momentum'\n",
    "os.chdir(importpath)\n",
    "\n",
    "stocks = pd.read_csv(importfile, encoding= 'unicode_escape')\n",
    "sdate = '2015-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  out of  505\n",
      "2  out of  505\n",
      "3  out of  505\n",
      "4  out of  505\n",
      "5  out of  505\n",
      "6  out of  505\n",
      "7  out of  505\n",
      "8  out of  505\n",
      "9  out of  505\n",
      "10  out of  505\n",
      "11  out of  505\n",
      "12  out of  505\n",
      "13  out of  505\n",
      "14  out of  505\n",
      "15  out of  505\n",
      "16  out of  505\n",
      "17  out of  505\n",
      "18  out of  505\n",
      "19  out of  505\n",
      "20  out of  505\n",
      "21  out of  505\n",
      "22  out of  505\n",
      "23  out of  505\n",
      "24  out of  505\n",
      "25  out of  505\n",
      "26  out of  505\n",
      "27  out of  505\n",
      "28  out of  505\n",
      "29  out of  505\n",
      "30  out of  505\n",
      "31  out of  505\n",
      "32  out of  505\n",
      "33  out of  505\n",
      "34  out of  505\n",
      "35  out of  505\n",
      "36  out of  505\n",
      "37  out of  505\n",
      "38  out of  505\n",
      "39  out of  505\n",
      "40  out of  505\n",
      "41  out of  505\n",
      "42  out of  505\n",
      "43  out of  505\n",
      "44  out of  505\n",
      "45  out of  505\n",
      "46  out of  505\n",
      "47  out of  505\n",
      "48  out of  505\n",
      "49  out of  505\n",
      "50  out of  505\n",
      "51  out of  505\n",
      "52  out of  505\n",
      "53  out of  505\n",
      "54  out of  505\n",
      "55  out of  505\n",
      "56  out of  505\n",
      "57  out of  505\n",
      "58  out of  505\n",
      "59  out of  505\n",
      "60  out of  505\n",
      "61  out of  505\n",
      "62  out of  505\n",
      "63  out of  505\n",
      "64  out of  505\n",
      "65  out of  505\n",
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "66  out of  505\n",
      "67  out of  505\n",
      "68  out of  505\n",
      "69  out of  505\n",
      "70  out of  505\n",
      "71  out of  505\n",
      "72  out of  505\n",
      "73  out of  505\n",
      "74  out of  505\n",
      "75  out of  505\n",
      "76  out of  505\n",
      "77  out of  505\n",
      "78  out of  505\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "79  out of  505\n",
      "80  out of  505\n",
      "81  out of  505\n",
      "82  out of  505\n",
      "83  out of  505\n",
      "84  out of  505\n",
      "85  out of  505\n",
      "86  out of  505\n",
      "87  out of  505\n",
      "88  out of  505\n",
      "89  out of  505\n",
      "90  out of  505\n",
      "91  out of  505\n",
      "92  out of  505\n",
      "93  out of  505\n",
      "94  out of  505\n",
      "95  out of  505\n",
      "96  out of  505\n",
      "97  out of  505\n",
      "98  out of  505\n",
      "99  out of  505\n",
      "100  out of  505\n",
      "101  out of  505\n",
      "102  out of  505\n",
      "103  out of  505\n",
      "104  out of  505\n",
      "105  out of  505\n",
      "106  out of  505\n",
      "107  out of  505\n",
      "108  out of  505\n",
      "109  out of  505\n",
      "110  out of  505\n",
      "111  out of  505\n",
      "112  out of  505\n",
      "113  out of  505\n",
      "114  out of  505\n",
      "115  out of  505\n",
      "116  out of  505\n",
      "117  out of  505\n",
      "118  out of  505\n",
      "119  out of  505\n",
      "120  out of  505\n",
      "121  out of  505\n",
      "122  out of  505\n",
      "123  out of  505\n",
      "124  out of  505\n",
      "125  out of  505\n",
      "126  out of  505\n",
      "127  out of  505\n",
      "128  out of  505\n",
      "129  out of  505\n",
      "130  out of  505\n",
      "131  out of  505\n",
      "132  out of  505\n",
      "133  out of  505\n",
      "134  out of  505\n",
      "135  out of  505\n",
      "136  out of  505\n",
      "137  out of  505\n",
      "138  out of  505\n",
      "139  out of  505\n",
      "140  out of  505\n",
      "141  out of  505\n",
      "142  out of  505\n",
      "143  out of  505\n",
      "144  out of  505\n",
      "145  out of  505\n",
      "146  out of  505\n",
      "147  out of  505\n",
      "148  out of  505\n",
      "149  out of  505\n",
      "150  out of  505\n",
      "151  out of  505\n",
      "152  out of  505\n",
      "153  out of  505\n",
      "154  out of  505\n",
      "155  out of  505\n",
      "156  out of  505\n",
      "157  out of  505\n",
      "158  out of  505\n",
      "159  out of  505\n",
      "160  out of  505\n",
      "161  out of  505\n",
      "162  out of  505\n",
      "163  out of  505\n",
      "164  out of  505\n",
      "165  out of  505\n",
      "166  out of  505\n",
      "167  out of  505\n",
      "168  out of  505\n",
      "169  out of  505\n",
      "170  out of  505\n",
      "171  out of  505\n",
      "172  out of  505\n",
      "173  out of  505\n",
      "174  out of  505\n",
      "175  out of  505\n",
      "176  out of  505\n",
      "177  out of  505\n",
      "178  out of  505\n",
      "179  out of  505\n",
      "180  out of  505\n",
      "181  out of  505\n",
      "182  out of  505\n",
      "183  out of  505\n",
      "184  out of  505\n",
      "185  out of  505\n",
      "186  out of  505\n",
      "187  out of  505\n",
      "188  out of  505\n",
      "189  out of  505\n",
      "190  out of  505\n",
      "191  out of  505\n",
      "192  out of  505\n",
      "193  out of  505\n",
      "194  out of  505\n",
      "195  out of  505\n",
      "196  out of  505\n",
      "197  out of  505\n",
      "198  out of  505\n",
      "199  out of  505\n",
      "200  out of  505\n",
      "201  out of  505\n",
      "202  out of  505\n",
      "203  out of  505\n",
      "204  out of  505\n",
      "205  out of  505\n",
      "206  out of  505\n",
      "207  out of  505\n",
      "208  out of  505\n",
      "209  out of  505\n",
      "210  out of  505\n",
      "211  out of  505\n",
      "212  out of  505\n",
      "213  out of  505\n",
      "214  out of  505\n",
      "215  out of  505\n",
      "216  out of  505\n",
      "217  out of  505\n",
      "218  out of  505\n",
      "219  out of  505\n",
      "220  out of  505\n",
      "221  out of  505\n",
      "222  out of  505\n",
      "223  out of  505\n",
      "224  out of  505\n",
      "225  out of  505\n",
      "226  out of  505\n",
      "227  out of  505\n",
      "228  out of  505\n",
      "229  out of  505\n",
      "230  out of  505\n",
      "231  out of  505\n",
      "232  out of  505\n",
      "233  out of  505\n",
      "234  out of  505\n",
      "235  out of  505\n",
      "236  out of  505\n",
      "237  out of  505\n",
      "238  out of  505\n",
      "239  out of  505\n",
      "240  out of  505\n",
      "241  out of  505\n",
      "242  out of  505\n",
      "243  out of  505\n",
      "244  out of  505\n",
      "245  out of  505\n",
      "246  out of  505\n",
      "247  out of  505\n",
      "248  out of  505\n",
      "249  out of  505\n",
      "250  out of  505\n",
      "251  out of  505\n",
      "252  out of  505\n",
      "253  out of  505\n",
      "254  out of  505\n",
      "255  out of  505\n",
      "256  out of  505\n",
      "257  out of  505\n",
      "258  out of  505\n",
      "259  out of  505\n",
      "260  out of  505\n",
      "261  out of  505\n",
      "262  out of  505\n",
      "263  out of  505\n",
      "264  out of  505\n",
      "265  out of  505\n",
      "266  out of  505\n",
      "267  out of  505\n",
      "268  out of  505\n",
      "269  out of  505\n",
      "270  out of  505\n",
      "271  out of  505\n",
      "272  out of  505\n",
      "273  out of  505\n",
      "274  out of  505\n",
      "275  out of  505\n",
      "276  out of  505\n",
      "277  out of  505\n",
      "278  out of  505\n",
      "279  out of  505\n",
      "280  out of  505\n",
      "281  out of  505\n",
      "282  out of  505\n",
      "283  out of  505\n",
      "284  out of  505\n",
      "285  out of  505\n",
      "286  out of  505\n",
      "287  out of  505\n",
      "288  out of  505\n",
      "289  out of  505\n",
      "290  out of  505\n",
      "291  out of  505\n",
      "292  out of  505\n",
      "293  out of  505\n",
      "294  out of  505\n",
      "295  out of  505\n",
      "296  out of  505\n",
      "297  out of  505\n",
      "298  out of  505\n",
      "299  out of  505\n",
      "300  out of  505\n",
      "301  out of  505\n",
      "302  out of  505\n",
      "303  out of  505\n",
      "304  out of  505\n",
      "305  out of  505\n",
      "306  out of  505\n",
      "307  out of  505\n",
      "308  out of  505\n",
      "309  out of  505\n",
      "310  out of  505\n",
      "311  out of  505\n",
      "312  out of  505\n",
      "313  out of  505\n",
      "314  out of  505\n",
      "315  out of  505\n",
      "316  out of  505\n",
      "317  out of  505\n",
      "318  out of  505\n",
      "319  out of  505\n",
      "320  out of  505\n",
      "321  out of  505\n",
      "322  out of  505\n",
      "323  out of  505\n",
      "324  out of  505\n",
      "325  out of  505\n",
      "326  out of  505\n",
      "327  out of  505\n",
      "328  out of  505\n",
      "329  out of  505\n",
      "330  out of  505\n",
      "331  out of  505\n",
      "332  out of  505\n",
      "333  out of  505\n",
      "334  out of  505\n",
      "335  out of  505\n",
      "336  out of  505\n",
      "337  out of  505\n",
      "338  out of  505\n",
      "339  out of  505\n",
      "340  out of  505\n",
      "341  out of  505\n",
      "342  out of  505\n",
      "343  out of  505\n",
      "344  out of  505\n",
      "345  out of  505\n",
      "346  out of  505\n",
      "347  out of  505\n",
      "348  out of  505\n",
      "349  out of  505\n",
      "350  out of  505\n",
      "351  out of  505\n",
      "352  out of  505\n",
      "353  out of  505\n",
      "354  out of  505\n",
      "355  out of  505\n",
      "356  out of  505\n",
      "357  out of  505\n",
      "358  out of  505\n",
      "359  out of  505\n",
      "360  out of  505\n",
      "361  out of  505\n",
      "362  out of  505\n",
      "363  out of  505\n",
      "364  out of  505\n",
      "365  out of  505\n",
      "366  out of  505\n",
      "367  out of  505\n",
      "368  out of  505\n",
      "369  out of  505\n",
      "370  out of  505\n",
      "371  out of  505\n",
      "372  out of  505\n",
      "373  out of  505\n",
      "374  out of  505\n",
      "375  out of  505\n",
      "376  out of  505\n",
      "377  out of  505\n",
      "378  out of  505\n",
      "379  out of  505\n",
      "380  out of  505\n",
      "381  out of  505\n",
      "382  out of  505\n",
      "383  out of  505\n",
      "384  out of  505\n",
      "385  out of  505\n",
      "386  out of  505\n",
      "387  out of  505\n",
      "388  out of  505\n",
      "389  out of  505\n",
      "390  out of  505\n",
      "391  out of  505\n",
      "392  out of  505\n",
      "393  out of  505\n",
      "394  out of  505\n",
      "395  out of  505\n",
      "396  out of  505\n",
      "397  out of  505\n",
      "398  out of  505\n",
      "399  out of  505\n",
      "400  out of  505\n",
      "401  out of  505\n",
      "402  out of  505\n",
      "403  out of  505\n",
      "404  out of  505\n",
      "405  out of  505\n",
      "406  out of  505\n",
      "407  out of  505\n",
      "408  out of  505\n",
      "409  out of  505\n",
      "410  out of  505\n",
      "411  out of  505\n",
      "412  out of  505\n",
      "413  out of  505\n",
      "414  out of  505\n",
      "415  out of  505\n",
      "416  out of  505\n",
      "417  out of  505\n",
      "418  out of  505\n",
      "419  out of  505\n",
      "420  out of  505\n",
      "421  out of  505\n",
      "422  out of  505\n",
      "423  out of  505\n",
      "424  out of  505\n",
      "425  out of  505\n",
      "426  out of  505\n",
      "427  out of  505\n",
      "428  out of  505\n",
      "429  out of  505\n",
      "430  out of  505\n",
      "431  out of  505\n",
      "432  out of  505\n",
      "433  out of  505\n",
      "434  out of  505\n",
      "435  out of  505\n",
      "436  out of  505\n",
      "437  out of  505\n",
      "438  out of  505\n",
      "439  out of  505\n",
      "440  out of  505\n",
      "441  out of  505\n",
      "442  out of  505\n",
      "443  out of  505\n",
      "444  out of  505\n",
      "445  out of  505\n",
      "446  out of  505\n",
      "447  out of  505\n",
      "448  out of  505\n",
      "449  out of  505\n",
      "450  out of  505\n",
      "451  out of  505\n",
      "452  out of  505\n",
      "453  out of  505\n",
      "454  out of  505\n",
      "455  out of  505\n",
      "456  out of  505\n",
      "457  out of  505\n",
      "458  out of  505\n",
      "459  out of  505\n",
      "460  out of  505\n",
      "461  out of  505\n",
      "462  out of  505\n",
      "463  out of  505\n",
      "464  out of  505\n",
      "465  out of  505\n",
      "466  out of  505\n",
      "467  out of  505\n",
      "468  out of  505\n",
      "469  out of  505\n",
      "470  out of  505\n",
      "471  out of  505\n",
      "472  out of  505\n",
      "473  out of  505\n",
      "474  out of  505\n",
      "475  out of  505\n",
      "476  out of  505\n",
      "477  out of  505\n",
      "478  out of  505\n",
      "479  out of  505\n",
      "480  out of  505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481  out of  505\n",
      "482  out of  505\n",
      "483  out of  505\n",
      "484  out of  505\n",
      "485  out of  505\n",
      "486  out of  505\n",
      "487  out of  505\n",
      "488  out of  505\n",
      "489  out of  505\n",
      "490  out of  505\n",
      "491  out of  505\n",
      "492  out of  505\n",
      "493  out of  505\n",
      "494  out of  505\n",
      "495  out of  505\n",
      "496  out of  505\n",
      "497  out of  505\n",
      "498  out of  505\n",
      "499  out of  505\n",
      "500  out of  505\n",
      "501  out of  505\n",
      "502  out of  505\n",
      "503  out of  505\n",
      "504  out of  505\n",
      "505  out of  505\n"
     ]
    }
   ],
   "source": [
    "# downloads stock data 1 at a time through loop and appends to dataframe\n",
    "# yfinance as the option to take an entire list at once, however I've found this method tends to time out if I'm using\n",
    "# a large set of stocks \n",
    "\n",
    "m = []\n",
    "tickers = stocks.Symbol\n",
    "n = 1\n",
    "for t in tickers:\n",
    "    try:\n",
    "        df = yf.download(t,sdate, progress = False, group_by = 'Ticker')\n",
    "        df['Ticker'] = t\n",
    "        print(n, ' out of ', len(tickers))\n",
    "        m.append(df)\n",
    "        n = n+1\n",
    "    except:\n",
    "        print(t, ' not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an archive of Daily Pricing Before running the Quantitative Analysis Functions. They take a while\n",
    "DailyPrices = pd.concat(m)\n",
    "DailyPrices.to_csv('Daily Pricing Detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantitative Analysis Functions\n",
    "\n",
    "\n",
    "\n",
    "def TR(row, axis = 1):\n",
    "    \n",
    "    H = row['High']\n",
    "    L = row['Low']\n",
    "    C = row['Close']\n",
    "    yC = row['yC']\n",
    "    \n",
    "    return max((H-L), abs(H-yC), abs(L-yC))\n",
    "\n",
    "\n",
    "\n",
    "def DM(row, axis = 1, d = 'PDM'):\n",
    "    \n",
    "    \n",
    "    tH = row['High']\n",
    "    yH = row['yH']\n",
    "    \n",
    "    tL = row['Low']\n",
    "    yL  = row['yL']\n",
    "    \n",
    "    moveUp = tH - yH\n",
    "    moveDown = yL - tL\n",
    "    \n",
    "    #calculate PDM\n",
    "    if moveUp > 0 and moveUp > moveDown:\n",
    "        PDM = moveUp\n",
    "    else:\n",
    "        PDM = 0\n",
    "    \n",
    "   #calculate NDM\n",
    "    if moveDown > 0 and moveDown > moveUp:\n",
    "        NDM = moveDown\n",
    "    else:\n",
    "        NDM = 0\n",
    "        \n",
    "    if d == 'PDM':\n",
    "        return PDM\n",
    "    else:\n",
    "        return NDM\n",
    "\n",
    "    \n",
    "def Smoothed(Metric, period, ADX = False):\n",
    "    \n",
    "    if ADX == False:\n",
    "        Base = Metric.rolling(window = period).mean()[period-1]\n",
    "    else:\n",
    "        Base = Metric.rolling(window = period).mean()[period*2 - 1]\n",
    "    \n",
    "    Metric = list(Metric)\n",
    "    period = period -1\n",
    "    lstlen = len(Metric)\n",
    "    lstSmoothed = np.empty(lstlen)\n",
    "\n",
    "    for i in range(lstlen):\n",
    "\n",
    "        if i < period:\n",
    "            lstSmoothed[i] = 0\n",
    "        elif i == period:\n",
    "            lstSmoothed[i] = Base\n",
    "        else:\n",
    "            lstSmoothed[i] = (lstSmoothed[i-1] * period + Metric[i])/(period + 1)\n",
    "\n",
    "\n",
    "    return lstSmoothed\n",
    "\n",
    "def Slope(Metric, lookback):\n",
    "    reg = LinearRegression()\n",
    "\n",
    "\n",
    "    time = np.arange(0,lookback,1)\n",
    "    lstlen = len(Metric)\n",
    "    sl = np.empty(lstlen)\n",
    "    \n",
    "    for i in range(lstlen):\n",
    "        \n",
    "        \n",
    "        \n",
    "        y = np.array(Metric[i-(lookback-1):(i+1)]).reshape(-1,1)\n",
    "        X = time.reshape(-1,1)\n",
    "        \n",
    "        if np.isnan(y).sum() > 0:\n",
    "            sl[i]=0\n",
    "        else:\n",
    "            \n",
    "            if len(y) == lookback:\n",
    "                reg.fit(X,y)\n",
    "                sl[i] = reg.coef_\n",
    "                \n",
    "                \n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Momentum(dfPrices):\n",
    "\n",
    "    m = []\n",
    "    tickers = list(dfPrices.Ticker.value_counts().index)\n",
    "    dfPrices = dfPrices.set_index('Date')\n",
    "    for t in tickers:\n",
    "        #try:\n",
    "            \n",
    "            df = dfPrices[dfPrices.Ticker == t]\n",
    "            df =df.drop(columns = 'Ticker')\n",
    "            \n",
    "            \n",
    "            df['yH'] = df[['High']].shift(1)\n",
    "            df['yL'] = df[['Low']].shift(1)\n",
    "            df['yC'] = df[['Close']].shift(1)\n",
    "\n",
    "            df['PDM'] = df.apply(DM, axis = 1, d='PDM')\n",
    "            df['NDM'] = df.apply(DM, axis = 1,d = 'NDM')\n",
    "            df['TR'] = df.apply(TR, axis = 1)\n",
    "\n",
    "            ATR = Smoothed(df['TR'], 14)\n",
    "            PDM_Smooth = Smoothed(df['PDM'], 14)\n",
    "            NDM_Smooth =Smoothed(df['NDM'], 14)\n",
    "            DI_Plus = PDM_Smooth/ATR * 100\n",
    "            DI_Neg = NDM_Smooth/ATR * 100\n",
    "            DI_Index =abs(DI_Plus - DI_Neg)/abs(DI_Plus+ DI_Neg) * 100\n",
    "            ADX =Smoothed(pd.Series(DI_Index), 14, ADX = True)\n",
    "\n",
    "\n",
    "            dfATR = pd.DataFrame(ATR, index = df.index, columns = ['ATR'])\n",
    "            dfDI_Plus = pd.DataFrame(DI_Plus, index = df.index, columns = ['DI_Plus'])\n",
    "            dfDI_Neg = pd.DataFrame(DI_Neg, index = df.index, columns = ['DI_Neg'])\n",
    "            ADX = pd.DataFrame(ADX, index = df.index, columns = ['ADX'])\n",
    "            dfNew = pd.concat([df,dfATR, dfDI_Plus, dfDI_Neg, ADX], axis = 1)\n",
    "\n",
    "            DIN_Slope = pd.DataFrame(Slope(dfNew.DI_Neg,7), index = dfNew.index, columns = ['DI_Neg_Slope'])\n",
    "            DIP_Slope = pd.DataFrame(Slope(dfNew.DI_Plus,7), index = dfNew.index, columns = ['DI_Plus_Slope'])\n",
    "\n",
    "            dfNew = pd.concat([dfNew, DIN_Slope, DIP_Slope ], axis = 1)\n",
    "\n",
    "\n",
    "            dfNew = dfNew[['Close', 'DI_Plus', 'DI_Neg', 'ADX', 'DI_Neg_Slope', 'DI_Plus_Slope']]\n",
    "            dfNew['SMA'] = dfNew['Close'].rolling(window = 20).mean()\n",
    "            dfNew['UpperB'] = dfNew.SMA + dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "            dfNew['LowerB'] = dfNew.SMA - dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "\n",
    "\n",
    "            dfNew['Off_SMA'] = (dfNew.Close - dfNew.SMA)/dfNew.SMA * 100\n",
    "            dfNew['Off_LB'] = (dfNew.Close - dfNew.LowerB)/dfNew.LowerB * 100\n",
    "            dfNew['Symbol'] = t\n",
    "            m.append(dfNew)\n",
    "        #except:\n",
    "         #   print(t, ' not found')\n",
    "            \n",
    "    \n",
    "    return pd.concat(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(importpath)\n",
    "DailyPrices = pd.read_csv('Daily Pricing Detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "Quant = Momentum(DailyPrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Final Analysis and Calculations. PE Ratio, Sales to Earnings, Industry Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quant = Quant.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 7 day forward looking price change\n",
    "\n",
    "QuantRev = Quant.sort_values(by = ['Symbol', 'Date'],ascending = (False,False))\n",
    "QuantRev['D'] = QuantRev['Close'].pct_change(periods = 7) * - 1\n",
    "Quant = QuantRev.sort_values(by = ['Symbol', 'Date'],ascending = (False,True))\n",
    "\n",
    "importpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData'\n",
    "os.chdir(importpath)\n",
    "\n",
    "#import datasets from cleaning\n",
    "fund = 'Fundamental_Final.csv'\n",
    "analyst = 'Analysts.csv'\n",
    "quant = 'Historical Quant Prices.csv'\n",
    "\n",
    "dfFund = pd.read_csv(fund).drop(columns = ['Unnamed: 0'])\n",
    "dfanalyst = pd.read_csv(analyst).drop(columns = ['Unnamed: 0'])\n",
    "dfquant = Quant\n",
    "\n",
    "dfquant = dfquant.rename(columns = {'Symbol':'Ticker'})\n",
    "dfFund['Key'] = dfFund[['index','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "dfquant['Year'] = pd.DatetimeIndex(dfquant['Date']).year - 1\n",
    "dfquant['Key'] = dfquant[['Year','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "#filter specific fields from fundamental sheet\n",
    "fields = ['Key','eps', 'ROE', 'Sector','D2C','epsgrowth', 'Sales', 'Shares']\n",
    "dfFund = dfFund[fields]\n",
    "\n",
    "#replace inf values from my ROE calculation\n",
    "dfFund['ROE'] = dfFund.ROE.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "#pull percent buy and ticker from the analyst rating data source\n",
    "dfRating = dfanalyst[['Symbol', 'Percent_Buy']]\n",
    "dfRating.columns = ['Ticker', 'Percent_Buy']\n",
    "\n",
    "\n",
    "#merge everyone together\n",
    "\n",
    "df = pd.merge(dfquant, dfFund, on = 'Key')\n",
    "df = pd.merge(df, dfRating, on = 'Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PE_Ratio'] = df.SMA/df.eps\n",
    "df.PE_Ratio = df.PE_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].mean())\n",
    "IQRPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75) - df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "\n",
    "peSector = pd.concat([AverageSectorPE, IQRPE, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "peSector.columns = ['Sector', 'AverageSectorPE','IQRPE','Quartile1','Quartile3' ]\n",
    "peSector['Upper'] = 1.5 * peSector.IQRPE + peSector.Quartile3\n",
    "peSector['Lower'] = 1.5 * peSector.IQRPE - peSector.Quartile1\n",
    "\n",
    "peSector = peSector[['Sector','AverageSectorPE', 'Upper', 'Lower']]\n",
    "df = pd.merge(df,peSector, on = 'Sector')\n",
    "df['Relative_PE'] = (df.PE_Ratio - df.AverageSectorPE) / df.AverageSectorPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales_Ratio'] = df.SMA/ (df.Sales/df.Shares)\n",
    "df.Sales_Ratio = df.Sales_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].mean())\n",
    "IQRSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75) - df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "srSector = pd.concat([AverageSectorSR, IQRSR, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "srSector.columns = ['Sector', 'AverageSectorSR','IQRSR','Quartile1','Quartile3' ]\n",
    "srSector['UpperSR'] = 1.5 * srSector.IQRSR + srSector.Quartile3\n",
    "srSector['LowerSR'] = 1.5 * srSector.IQRSR - srSector.Quartile1\n",
    "\n",
    "SR = srSector[['Sector', 'AverageSectorSR', 'UpperSR', 'LowerSR']]\n",
    "df = pd.merge(df,SR, on = 'Sector')\n",
    "df['Relative_SR'] = (df.Sales_Ratio - df.AverageSectorSR) / df.AverageSectorSR\n",
    "df['Relative_SR'] = df['Relative_SR'].fillna(0)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(exportpath)\n",
    "df.to_csv('Historical Quant Prices.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondaa8b2bb7a1475404398bd16ebfacc95c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
