{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling - Optinal append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete the next  two cells if you'd like to append additional stock data to your historical pricing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Day:  2/9/2018\n"
     ]
    }
   ],
   "source": [
    "#import Historical Pricing Data compiled from mass yahoo download\n",
    "os.chdir(r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData')\n",
    "dfHistorical = pd.read_csv('Daily Pricing Detail.csv').dropna()\n",
    "#dfHistQuant = pd.read_csv('Historical Quant Prices.csv')\n",
    "print('Last Day: ', dfHistQuant.Date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import S&P stocks to download\n",
    "importpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\Stock Import Lists'\n",
    "importfile = 'SandP.csv'\n",
    "exportpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData'\n",
    "exportfile = 'Momentum'\n",
    "os.chdir(importpath)\n",
    "\n",
    "stocks = pd.read_csv(importfile, encoding= 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define date for new stock price download\n",
    "\n",
    "edate = '2020-08-11'\n",
    "sdate = '2020-08-10'\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  505 of 505 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- BRK.B: No data found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#download new stock data\n",
    "df = yf.download(list(stocks.Symbol), start = sdate, end = edate, progress = True ).reset_index()\n",
    "# Melt and Pivot for proper formatting\n",
    "df = df.melt(id_vars = 'Date', var_name = ['Type', 'Ticker']).set_index(['Date','Ticker']).pivot(columns = 'Type').reset_index()\n",
    "df.columns = df.columns.droplevel(0)\n",
    "columns = list(df.columns)\n",
    "columns[0] = 'Date'\n",
    "columns[1] = 'Ticker'\n",
    "df.columns = columns\n",
    "df = df.sort_values(by = ['Ticker', 'Date'])\n",
    "df = df.dropna()\n",
    "\n",
    "    \n",
    "#append to historical list\n",
    "df = df[dfHistorical.columns]\n",
    "dfNew = pd.concat([dfHistorical, df])\n",
    "dfNew.Date = pd.to_datetime(dfNew.Date)\n",
    "dfNew = dfNew.sort_values(by = ['Ticker', 'Date'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNew.to_csv('Daily Pricing Detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantitative Analysis Functions\n",
    "\n",
    "\n",
    "\n",
    "def TR(row, axis = 1):\n",
    "    \n",
    "    H = row['High']\n",
    "    L = row['Low']\n",
    "    C = row['Close']\n",
    "    yC = row['yC']\n",
    "    \n",
    "    return max((H-L), abs(H-yC), abs(L-yC))\n",
    "\n",
    "\n",
    "\n",
    "def DM(row, axis = 1, d = 'PDM'):\n",
    "    \n",
    "    \n",
    "    tH = row['High']\n",
    "    yH = row['yH']\n",
    "    \n",
    "    tL = row['Low']\n",
    "    yL  = row['yL']\n",
    "    \n",
    "    moveUp = tH - yH\n",
    "    moveDown = yL - tL\n",
    "    \n",
    "    #calculate PDM\n",
    "    if moveUp > 0 and moveUp > moveDown:\n",
    "        PDM = moveUp\n",
    "    else:\n",
    "        PDM = 0\n",
    "    \n",
    "   #calculate NDM\n",
    "    if moveDown > 0 and moveDown > moveUp:\n",
    "        NDM = moveDown\n",
    "    else:\n",
    "        NDM = 0\n",
    "        \n",
    "    if d == 'PDM':\n",
    "        return PDM\n",
    "    else:\n",
    "        return NDM\n",
    "\n",
    "    \n",
    "def Smoothed(Metric, period, ADX = False):\n",
    "    \n",
    "    if ADX == False:\n",
    "        Base = Metric.rolling(window = period).mean()[period-1]\n",
    "    else:\n",
    "        Base = Metric.rolling(window = period).mean()[period*2 - 1]\n",
    "    \n",
    "    Metric = list(Metric)\n",
    "    period = period -1\n",
    "    lstlen = len(Metric)\n",
    "    lstSmoothed = np.empty(lstlen)\n",
    "\n",
    "    for i in range(lstlen):\n",
    "\n",
    "        if i < period:\n",
    "            lstSmoothed[i] = 0\n",
    "        elif i == period:\n",
    "            lstSmoothed[i] = Base\n",
    "        else:\n",
    "            lstSmoothed[i] = (lstSmoothed[i-1] * period + Metric[i])/(period + 1)\n",
    "\n",
    "\n",
    "    return lstSmoothed\n",
    "\n",
    "def Slope(Metric, lookback):\n",
    "    reg = LinearRegression()\n",
    "\n",
    "\n",
    "    time = np.arange(0,lookback,1)\n",
    "    lstlen = len(Metric)\n",
    "    sl = np.empty(lstlen)\n",
    "    \n",
    "    for i in range(lstlen):\n",
    "        \n",
    "        \n",
    "        \n",
    "        y = np.array(Metric[i-(lookback-1):(i+1)]).reshape(-1,1)\n",
    "        X = time.reshape(-1,1)\n",
    "        \n",
    "        if np.isnan(y).sum() > 0:\n",
    "            sl[i]=0\n",
    "        else:\n",
    "            \n",
    "            if len(y) == lookback:\n",
    "                reg.fit(X,y)\n",
    "                sl[i] = reg.coef_\n",
    "                \n",
    "                \n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Momentum(dfPrices):\n",
    "\n",
    "    m = []\n",
    "    tickers = list(dfPrices.Ticker.value_counts().index)\n",
    "    dfPrices = dfPrices.set_index('Date')\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            \n",
    "            df = dfPrices[dfPrices.Ticker == t]\n",
    "            df =df.drop(columns = 'Ticker')\n",
    "            \n",
    "            \n",
    "            df['yH'] = df[['High']].shift(1)\n",
    "            df['yL'] = df[['Low']].shift(1)\n",
    "            df['yC'] = df[['Close']].shift(1)\n",
    "\n",
    "            df['PDM'] = df.apply(DM, axis = 1, d='PDM')\n",
    "            df['NDM'] = df.apply(DM, axis = 1,d = 'NDM')\n",
    "            df['TR'] = df.apply(TR, axis = 1)\n",
    "\n",
    "            ATR = Smoothed(df['TR'], 14)\n",
    "            PDM_Smooth = Smoothed(df['PDM'], 14)\n",
    "            NDM_Smooth =Smoothed(df['NDM'], 14)\n",
    "            DI_Plus = PDM_Smooth/ATR * 100\n",
    "            DI_Neg = NDM_Smooth/ATR * 100\n",
    "            DI_Index =abs(DI_Plus - DI_Neg)/abs(DI_Plus+ DI_Neg) * 100\n",
    "            ADX =Smoothed(pd.Series(DI_Index), 14, ADX = True)\n",
    "\n",
    "\n",
    "            dfATR = pd.DataFrame(ATR, index = df.index, columns = ['ATR'])\n",
    "            dfDI_Plus = pd.DataFrame(DI_Plus, index = df.index, columns = ['DI_Plus'])\n",
    "            dfDI_Neg = pd.DataFrame(DI_Neg, index = df.index, columns = ['DI_Neg'])\n",
    "            ADX = pd.DataFrame(ADX, index = df.index, columns = ['ADX'])\n",
    "            dfNew = pd.concat([df,dfATR, dfDI_Plus, dfDI_Neg, ADX], axis = 1)\n",
    "\n",
    "            DIN_Slope = pd.DataFrame(Slope(dfNew.DI_Neg,7), index = dfNew.index, columns = ['DI_Neg_Slope'])\n",
    "            DIP_Slope = pd.DataFrame(Slope(dfNew.DI_Plus,7), index = dfNew.index, columns = ['DI_Plus_Slope'])\n",
    "\n",
    "            dfNew = pd.concat([dfNew, DIN_Slope, DIP_Slope ], axis = 1)\n",
    "\n",
    "\n",
    "            dfNew = dfNew[['Close', 'DI_Plus', 'DI_Neg', 'ADX', 'DI_Neg_Slope', 'DI_Plus_Slope']]\n",
    "            dfNew['SMA'] = dfNew['Close'].rolling(window = 20).mean()\n",
    "            dfNew['UpperB'] = dfNew.SMA + dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "            dfNew['LowerB'] = dfNew.SMA - dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "\n",
    "\n",
    "            dfNew['Off_SMA'] = (dfNew.Close - dfNew.SMA)/dfNew.SMA * 100\n",
    "            dfNew['Off_LB'] = (dfNew.Close - dfNew.LowerB)/dfNew.LowerB * 100\n",
    "            dfNew['Symbol'] = t\n",
    "            m.append(dfNew)\n",
    "        except:\n",
    "            print(t, ' not found')\n",
    "            \n",
    "    \n",
    "    return pd.concat(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "#calculate new metrics\n",
    "#need a solid year of data to properly calculate ADX, DI_Plus, DI_Neg\n",
    "\n",
    "tday = datetime.today()\n",
    "delta = tday - timedelta(200)\n",
    "\n",
    "datefilter = dfNew.Date > delta\n",
    "Quant = Momentum(dfNew[datefilter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewQuant = Quant.reset_index()\n",
    "#Quant = Quant[Quant.Date > lastday]\n",
    "#Quant.Date = pd.to_datetime(Quant.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = pd.concat([dfHistQuant, Quant])\n",
    "NewQuant = NewQuant.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 7 day forward looking price change\n",
    "\n",
    "QuantRev = NewQuant.sort_values(by = ['Symbol', 'Date'],ascending = (False,False))\n",
    "QuantRev['D'] = QuantRev['Close'].pct_change(periods = 7) * - 1\n",
    "NewQuant = QuantRev.sort_values(by = ['Symbol', 'Date'],ascending = (False,True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "importpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData'\n",
    "os.chdir(importpath)\n",
    "\n",
    "#import datasets from cleaning\n",
    "fund = 'Fundamental_Final.csv'\n",
    "analyst = 'Analysts.csv'\n",
    "quant = 'Historical Quant Prices.csv'\n",
    "\n",
    "dfFund = pd.read_csv(fund).drop(columns = ['Unnamed: 0'])\n",
    "dfanalyst = pd.read_csv(analyst).drop(columns = ['Unnamed: 0'])\n",
    "dfquant = NewQuant\n",
    "\n",
    "dfquant = dfquant.rename(columns = {'Symbol':'Ticker'})\n",
    "dfFund['Key'] = dfFund[['index','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "dfquant['Year'] = pd.DatetimeIndex(dfquant['Date']).year - 1\n",
    "dfquant['Key'] = dfquant[['Year','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "#filter specific fields from fundamental sheet\n",
    "fields = ['Key','eps', 'ROE', 'Sector','D2C','epsgrowth', 'Sales', 'Shares']\n",
    "dfFund = dfFund[fields]\n",
    "\n",
    "#replace inf values from my ROE calculation\n",
    "dfFund['ROE'] = dfFund.ROE.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "#pull percent buy and ticker from the analyst rating data source\n",
    "dfRating = dfanalyst[['Symbol', 'Percent_Buy']]\n",
    "dfRating.columns = ['Ticker', 'Percent_Buy']\n",
    "\n",
    "\n",
    "#merge everyone together\n",
    "\n",
    "df = pd.merge(dfquant, dfFund, on = 'Key')\n",
    "df = pd.merge(df, dfRating, on = 'Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PE_Ratio'] = df.SMA/df.eps\n",
    "df.PE_Ratio = df.PE_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].mean())\n",
    "IQRPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75) - df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "\n",
    "peSector = pd.concat([AverageSectorPE, IQRPE, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "peSector.columns = ['Sector', 'AverageSectorPE','IQRPE','Quartile1','Quartile3' ]\n",
    "peSector['Upper'] = 1.5 * peSector.IQRPE + peSector.Quartile3\n",
    "peSector['Lower'] = 1.5 * peSector.IQRPE - peSector.Quartile1\n",
    "\n",
    "peSector = peSector[['Sector','AverageSectorPE', 'Upper', 'Lower']]\n",
    "df = pd.merge(df,peSector, on = 'Sector')\n",
    "df['Relative_PE'] = (df.PE_Ratio - df.AverageSectorPE) / df.AverageSectorPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sales_Ratio'] = df.SMA/ (df.Sales/df.Shares)\n",
    "df.Sales_Ratio = df.Sales_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].mean())\n",
    "IQRSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75) - df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "srSector = pd.concat([AverageSectorSR, IQRSR, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "srSector.columns = ['Sector', 'AverageSectorSR','IQRSR','Quartile1','Quartile3' ]\n",
    "srSector['UpperSR'] = 1.5 * srSector.IQRSR + srSector.Quartile3\n",
    "srSector['LowerSR'] = 1.5 * srSector.IQRSR - srSector.Quartile1\n",
    "\n",
    "SR = srSector[['Sector', 'AverageSectorSR', 'UpperSR', 'LowerSR']]\n",
    "df = pd.merge(df,SR, on = 'Sector')\n",
    "df['Relative_SR'] = (df.Sales_Ratio - df.AverageSectorSR) / df.AverageSectorSR\n",
    "df['Relative_SR'] = df['Relative_SR'].fillna(0)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "year = now.strftime(\"%Y\")\n",
    "month = now.strftime(\"%m\")\n",
    "day = now.strftime(\"%d\")\n",
    "\n",
    "filename = 'Quant Prices_' +  str(year) + '_' +  str(month) + '_' + str(day) + '.csv'\n",
    "os.chdir(exportpath)\n",
    "\n",
    "df.to_csv(filename)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondaa8b2bb7a1475404398bd16ebfacc95c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
