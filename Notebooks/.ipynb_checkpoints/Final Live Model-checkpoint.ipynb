{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\Stock Import Lists'\n",
    "importfile = 'SandP.csv'\n",
    "exportpath = r'C:\\Users\\nmur1\\Google Drive\\Springboard\\Capstone2\\CleanData'\n",
    "exportfile = 'Momentum'\n",
    "os.chdir(importpath)\n",
    "\n",
    "stocks = pd.read_csv(importfile, encoding= 'unicode_escape')\n",
    "\n",
    "\n",
    "#Quantitative Analysis Functions\n",
    "\n",
    "\n",
    "\n",
    "def TR(row, axis = 1):\n",
    "    \n",
    "    H = row['High']\n",
    "    L = row['Low']\n",
    "    C = row['Close']\n",
    "    yC = row['yC']\n",
    "    \n",
    "    return max((H-L), abs(H-yC), abs(L-yC))\n",
    "\n",
    "\n",
    "\n",
    "def DM(row, axis = 1, d = 'PDM'):\n",
    "    \n",
    "    \n",
    "    tH = row['High']\n",
    "    yH = row['yH']\n",
    "    \n",
    "    tL = row['Low']\n",
    "    yL  = row['yL']\n",
    "    \n",
    "    moveUp = tH - yH\n",
    "    moveDown = yL - tL\n",
    "    \n",
    "    #calculate PDM\n",
    "    if moveUp > 0 and moveUp > moveDown:\n",
    "        PDM = moveUp\n",
    "    else:\n",
    "        PDM = 0\n",
    "    \n",
    "   #calculate NDM\n",
    "    if moveDown > 0 and moveDown > moveUp:\n",
    "        NDM = moveDown\n",
    "    else:\n",
    "        NDM = 0\n",
    "        \n",
    "    if d == 'PDM':\n",
    "        return PDM\n",
    "    else:\n",
    "        return NDM\n",
    "\n",
    "    \n",
    "def Smoothed(Metric, period, ADX = False):\n",
    "    \n",
    "    if ADX == False:\n",
    "        Base = Metric.rolling(window = period).mean()[period-1]\n",
    "    else:\n",
    "        Base = Metric.rolling(window = period).mean()[period*2 - 1]\n",
    "    \n",
    "    Metric = list(Metric)\n",
    "    period = period -1\n",
    "    lstlen = len(Metric)\n",
    "    lstSmoothed = np.empty(lstlen)\n",
    "\n",
    "    for i in range(lstlen):\n",
    "\n",
    "        if i < period:\n",
    "            lstSmoothed[i] = 0\n",
    "        elif i == period:\n",
    "            lstSmoothed[i] = Base\n",
    "        else:\n",
    "            lstSmoothed[i] = (lstSmoothed[i-1] * period + Metric[i])/(period + 1)\n",
    "\n",
    "\n",
    "    return lstSmoothed\n",
    "\n",
    "def Slope(Metric, lookback):\n",
    "    reg = LinearRegression()\n",
    "\n",
    "\n",
    "    time = np.arange(0,lookback,1)\n",
    "    lstlen = len(Metric)\n",
    "    sl = np.empty(lstlen)\n",
    "    \n",
    "    for i in range(lstlen):\n",
    "        \n",
    "        \n",
    "        \n",
    "        y = np.array(Metric[i-(lookback-1):(i+1)]).reshape(-1,1)\n",
    "        X = time.reshape(-1,1)\n",
    "        \n",
    "        if np.isnan(y).sum() > 0:\n",
    "            sl[i]=0\n",
    "        else:\n",
    "            \n",
    "            if len(y) == lookback:\n",
    "                reg.fit(X,y)\n",
    "                sl[i] = reg.coef_\n",
    "                \n",
    "                \n",
    "    return sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Momentum(tickers, sdate):\n",
    "\n",
    "    m = []\n",
    "    \n",
    "    for t in tickers:\n",
    "        try:\n",
    "            df = yf.download(t,sdate, progress = False, group_by = 'Ticker')\n",
    "        \n",
    "            df['yH'] = df[['High']].shift(1)\n",
    "            df['yL'] = df[['Low']].shift(1)\n",
    "            df['yC'] = df[['Close']].shift(1)\n",
    "\n",
    "            df['PDM'] = df.apply(DM, axis = 1, d='PDM')\n",
    "            df['NDM'] = df.apply(DM, axis = 1,d = 'NDM')\n",
    "            df['TR'] = df.apply(TR, axis = 1)\n",
    "\n",
    "            ATR = Smoothed(df['TR'], 14)\n",
    "            PDM_Smooth = Smoothed(df['PDM'], 14)\n",
    "            NDM_Smooth =Smoothed(df['NDM'], 14)\n",
    "            DI_Plus = PDM_Smooth/ATR * 100\n",
    "            DI_Neg = NDM_Smooth/ATR * 100\n",
    "            DI_Index =abs(DI_Plus - DI_Neg)/abs(DI_Plus+ DI_Neg) * 100\n",
    "            ADX =Smoothed(pd.Series(DI_Index), 14, ADX = True)\n",
    "\n",
    "\n",
    "            dfATR = pd.DataFrame(ATR, index = df.index, columns = ['ATR'])\n",
    "            dfDI_Plus = pd.DataFrame(DI_Plus, index = df.index, columns = ['DI_Plus'])\n",
    "            dfDI_Neg = pd.DataFrame(DI_Neg, index = df.index, columns = ['DI_Neg'])\n",
    "            ADX = pd.DataFrame(ADX, index = df.index, columns = ['ADX'])\n",
    "            dfNew = pd.concat([df,dfATR, dfDI_Plus, dfDI_Neg, ADX], axis = 1)\n",
    "\n",
    "            DIN_Slope = pd.DataFrame(Slope(dfNew.DI_Neg,7), index = dfNew.index, columns = ['DI_Neg_Slope'])\n",
    "            DIP_Slope = pd.DataFrame(Slope(dfNew.DI_Plus,7), index = dfNew.index, columns = ['DI_Plus_Slope'])\n",
    "\n",
    "            dfNew = pd.concat([dfNew, DIN_Slope, DIP_Slope ], axis = 1)\n",
    "\n",
    "\n",
    "            dfNew = dfNew[['Close', 'DI_Plus', 'DI_Neg', 'ADX', 'DI_Neg_Slope', 'DI_Plus_Slope']]\n",
    "            dfNew['SMA'] = dfNew['Close'].rolling(window = 20).mean()\n",
    "            dfNew['UpperB'] = dfNew.SMA + dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "            dfNew['LowerB'] = dfNew.SMA - dfNew['Close'].rolling(window = 20).agg(np.std, ddof = 0) * 2\n",
    "\n",
    "\n",
    "            dfNew['Off_SMA'] = (dfNew.Close - dfNew.SMA)/dfNew.SMA * 100\n",
    "            dfNew['Off_LB'] = (dfNew.Close - dfNew.LowerB)/dfNew.LowerB * 100\n",
    "            dfNew['Symbol'] = t\n",
    "            m.append(dfNew)\n",
    "        except:\n",
    "            print(t, ' not found')\n",
    "            \n",
    "    \n",
    "    return pd.concat(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- BRK.B: No data found, symbol may be delisted\n",
      "BRK.B  not found\n",
      "\n",
      "1 Failed download:\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "BF.B  not found\n",
      "KIM  not found\n",
      "KMI  not found\n",
      "KLAC  not found\n",
      "KSS  not found\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "stocklist = stocks.Symbol\n",
    "Quant = Momentum(stocklist, '2019-06-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QuantRev = Quant.sort_values(by = ['Symbol', 'Date'],ascending = (False,False))\n",
    "QuantRev['D'] = QuantRev['Close'].pct_change(periods = 7) * - 1\n",
    "Quant = QuantRev.sort_values(by = ['Symbol', 'Date'],ascending = (False,True))\n",
    "Quant = Quant.dropna()\n",
    "os.chdir(exportpath)\n",
    "Quant.to_csv('Live_Quant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets from cleaning\n",
    "fund = 'Fundamental_Final.csv'\n",
    "analyst = 'Analysts.csv'\n",
    "quant = 'Quant_Pricing.csv'\n",
    "\n",
    "dfFund = pd.read_csv(fund).drop(columns = ['Unnamed: 0'])\n",
    "dfanalyst = pd.read_csv(analyst).drop(columns = ['Unnamed: 0'])\n",
    "dfquant = Quant.reset_index()\n",
    "\n",
    "dfquant = dfquant.rename(columns = {'Symbol':'Ticker'})\n",
    "dfFund['Key'] = dfFund[['index','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "dfquant['Year'] = pd.DatetimeIndex(dfquant['Date']).year - 1\n",
    "dfquant['Key'] = dfquant[['Year','Ticker']].astype(str).apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "#filter specific fields from fundamental sheet\n",
    "fields = ['Key','eps', 'ROE', 'Sector','D2C','epsgrowth', 'Sales', 'Shares']\n",
    "dfFund = dfFund[fields]\n",
    "\n",
    "#replace inf values from my ROE calculation\n",
    "dfFund['ROE'] = dfFund.ROE.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "\n",
    "#pull percent buy and ticker from the analyst rating data source\n",
    "dfRating = dfanalyst[['Symbol', 'Percent_Buy']]\n",
    "dfRating.columns = ['Ticker', 'Percent_Buy']\n",
    "\n",
    "\n",
    "#merge everyone together\n",
    "\n",
    "df = pd.merge(dfquant, dfFund, on = 'Key')\n",
    "df = pd.merge(df, dfRating, on = 'Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PE_Ratio'] = df.SMA/df.eps\n",
    "df.PE_Ratio = df.PE_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].mean())\n",
    "IQRPE = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75) - df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['PE_Ratio'].quantile(.25))\n",
    "\n",
    "peSector = pd.concat([AverageSectorPE, IQRPE, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "peSector.columns = ['Sector', 'AverageSectorPE','IQRPE','Quartile1','Quartile3' ]\n",
    "peSector['Upper'] = 1.5 * peSector.IQRPE + peSector.Quartile3\n",
    "peSector['Lower'] = 1.5 * peSector.IQRPE - peSector.Quartile1\n",
    "\n",
    "peSector = peSector[['Sector','AverageSectorPE', 'Upper', 'Lower']]\n",
    "df = pd.merge(df,peSector, on = 'Sector')\n",
    "df['Relative_PE'] = (df.PE_Ratio - df.AverageSectorPE) / df.AverageSectorPE\n",
    "\n",
    "df['Sales_Ratio'] = df.SMA/ (df.Sales/df.Shares)\n",
    "df.Sales_Ratio = df.Sales_Ratio.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "AverageSectorSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].mean())\n",
    "IQRSR = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75) - df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "Quartile3 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.75))\n",
    "Quartile1 = pd.DataFrame(df.groupby('Sector')['Sales_Ratio'].quantile(.25))\n",
    "srSector = pd.concat([AverageSectorSR, IQRSR, Quartile1, Quartile3], axis = 1).reset_index()\n",
    "srSector.columns = ['Sector', 'AverageSectorSR','IQRSR','Quartile1','Quartile3' ]\n",
    "srSector['UpperSR'] = 1.5 * srSector.IQRSR + srSector.Quartile3\n",
    "srSector['LowerSR'] = 1.5 * srSector.IQRSR - srSector.Quartile1\n",
    "\n",
    "SR = srSector[['Sector', 'AverageSectorSR', 'UpperSR', 'LowerSR']]\n",
    "df = pd.merge(df,SR, on = 'Sector')\n",
    "df['Relative_SR'] = (df.Sales_Ratio - df.AverageSectorSR) / df.AverageSectorSR\n",
    "df['Relative_SR'] = df['Relative_SR'].fillna(0)\n",
    "df['month'] = pd.DatetimeIndex(df['Date']).month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(df, drop):\n",
    "\n",
    "    df2 = df.drop(columns = drop)\n",
    "    ds = pd.get_dummies(df[drop])\n",
    "    dfdum = pd.concat([df2, ds], axis = 1)\n",
    "\n",
    "    return dfdum\n",
    "\n",
    "Model = dummy(df, ['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todrop = ['Ticker','Date', 'Key','D','AverageSectorSR','Year', 'Sales_Ratio','DI_Neg_Slope','eps','LowerB', 'UpperSR', 'LowerSR','month',\n",
    "                         'Sales','Shares','UpperB', 'DI_Plus', 'DI_Neg', 'SMA', 'Close','AverageSectorPE', 'PE_Ratio', 'Upper', 'Lower']\n",
    "\n",
    "\n",
    "\n",
    "#filter date, eps greater than zero, and outlying Sales Ratios\n",
    "Model = Model[Model.Date == '2020-08-07']\n",
    "Model = Model[Model.eps > 0]\n",
    "Model = Model[(Model.Sales_Ratio > Model.LowerSR) & (Model.Sales_Ratio < Model.UpperSR)]\n",
    "\n",
    "#Make a copy of the metadata\n",
    "X_Meta = Model\n",
    "\n",
    "#Finalize the live X Variable\n",
    "X_Live = Model.drop(columns = todrop)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Sales = pd.read_csv('Final_Final_Model_Set.csv')\n",
    "X = df_Sales.drop(columns = ['Date','Ticker', 'Dir_Binary','Dir_Multi' ,'Key','Unnamed: 0'])\n",
    "y = df_Sales['Dir_Binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(100, n_jobs = -1, random_state = 42, min_samples_leaf = 1, criterion = \"gini\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "ypred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "false_positives = confusion_matrix(y_test, ypred)[0][1]\n",
    "print('False Positives in Test:', false_positives)\n",
    "print(\"Chance of FP's \", round(false_positives / len(y_test),4) * 100)\n",
    "\n",
    "\n",
    "print('ROC:', round(roc_auc_score(y_test, ypred),3))\n",
    "print('Accuracy', round(accuracy_score(y_test,ypred),3))\n",
    "print('Recall', round(recall_score(y_test, ypred),3))\n",
    "print('Precision', round(precision_score(y_test, ypred),3))\n",
    "print('F1', round(f1_score(y_test, ypred),3))\n",
    "\n",
    "pd.reset_option('display.float_format')\n",
    "confmat = plot_confusion_matrix(model, X_test, y_test, cmap=\"Blues\",values_format='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_Live = X_Live.drop(columns = 'Ticker')\n",
    "except:\n",
    "    print('Already Dropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_Live)\n",
    "predictions = pd.DataFrame(model.predict_proba(X_Live))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final = pd.concat([X_Meta.reset_index(), predictions], axis = 1).set_index('Ticker')\n",
    "Final.to_csv('Fianl_Predicitons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondaa8b2bb7a1475404398bd16ebfacc95c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
